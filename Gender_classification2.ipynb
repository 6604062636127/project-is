{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "collapsed": true,
        "id": "6ogXocZWH7yD",
        "outputId": "3cf2678f-2ab5-4d2d-ca96-e3829230bd53"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d humairmunir/gender-recognizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtLmZIF3JGMd",
        "outputId": "58b8d5bb-f674-4c59-a6ff-a2470e58873d"
      },
      "outputs": [],
      "source": [
        "!unzip gender-recognizer.zip -d gender_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1bc3rdQJDCU"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"gender_data/dataset/WOMAN/MEN\", ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkWlRxYPTf-z",
        "outputId": "21c57177-84e9-4259-ba4f-e723e97b0fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MEN: 452\n",
            "Train WOMAN: 452\n",
            "Valid MEN: 96\n",
            "Valid WOMAN: 96\n",
            "Test MEN: 98\n",
            "Test WOMAN: 98\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# กำหนดเส้นทางของ dataset\n",
        "dataset_path = \"gender_data/dataset\"\n",
        "train_path = \"gender_train\"\n",
        "valid_path = \"gender_valid\"\n",
        "test_path = \"gender_test\"  # เพิ่มโฟลเดอร์ Test Data\n",
        "\n",
        "# ลบข้อมูลเก่า\n",
        "shutil.rmtree(train_path, ignore_errors=True)\n",
        "shutil.rmtree(valid_path, ignore_errors=True)\n",
        "shutil.rmtree(test_path, ignore_errors=True)  # ลบ test_path ด้วย\n",
        "\n",
        "# สร้างโฟลเดอร์สำหรับ train, validation และ test\n",
        "for category in [\"MEN\", \"WOMAN\"]:\n",
        "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(valid_path, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, category), exist_ok=True)  # สร้างโฟลเดอร์ Test Data\n",
        "\n",
        "# ฟังก์ชันแบ่งข้อมูลเป็น Train 70%, Validation 15%, Test 15%\n",
        "def split_data(source, train_dir, valid_dir, test_dir, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15):\n",
        "    files = [f for f in os.listdir(source) if os.path.isfile(os.path.join(source, f))]\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_size = int(len(files) * train_ratio)\n",
        "    valid_size = int(len(files) * valid_ratio)\n",
        "\n",
        "    train_files = files[:train_size]\n",
        "    valid_files = files[train_size:train_size + valid_size]\n",
        "    test_files = files[train_size + valid_size:]  \n",
        "\n",
        "    # คัดลอกไฟล์ไปยัง Train\n",
        "    for file in train_files:\n",
        "        shutil.copy2(os.path.join(source, file), os.path.join(train_dir, file))\n",
        "\n",
        "    # คัดลอกไฟล์ไปยัง Validation\n",
        "    for file in valid_files:\n",
        "        shutil.copy2(os.path.join(source, file), os.path.join(valid_dir, file))\n",
        "\n",
        "    # คัดลอกไฟล์ไปยัง Test\n",
        "    for file in test_files:\n",
        "        shutil.copy2(os.path.join(source, file), os.path.join(test_dir, file))\n",
        "\n",
        "split_data(\n",
        "    os.path.join(dataset_path, \"MEN\"),\n",
        "    os.path.join(train_path, \"MEN\"),\n",
        "    os.path.join(valid_path, \"MEN\"),\n",
        "    os.path.join(test_path, \"MEN\")\n",
        ")\n",
        "\n",
        "split_data(\n",
        "    os.path.join(dataset_path, \"WOMAN\"),\n",
        "    os.path.join(train_path, \"WOMAN\"),\n",
        "    os.path.join(valid_path, \"WOMAN\"),\n",
        "    os.path.join(test_path, \"WOMAN\")\n",
        ")\n",
        "\n",
        "print(f\"Train MEN: {len(os.listdir(train_path+'/MEN'))}\")\n",
        "print(f\"Train WOMAN: {len(os.listdir(train_path+'/WOMAN'))}\")\n",
        "print(f\"Valid MEN: {len(os.listdir(valid_path+'/MEN'))}\")\n",
        "print(f\"Valid WOMAN: {len(os.listdir(valid_path+'/WOMAN'))}\")\n",
        "print(f\"Test MEN: {len(os.listdir(test_path+'/MEN'))}\")\n",
        "print(f\"Test WOMAN: {len(os.listdir(test_path+'/WOMAN'))}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2J8bHpzaEmP",
        "outputId": "a7120730-b949-42dd-fca3-493fbbccd08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 903 images belonging to 2 classes.\n",
            "Found 192 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load Data\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "nbIT9S_fVrsJ",
        "outputId": "b062ccb6-ce48-4b77-94a8-12441975b822"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# สร้างโมเดล CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# คอมไพล์โมเดล\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# แสดงโครงสร้างโมเดล\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rVyAyUG3VxVZ",
        "outputId": "34220664-74ba-48aa-d10a-19057cda5089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.5276 - loss: 8.7870 - val_accuracy: 0.5052 - val_loss: 2.2369 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.5958 - loss: 2.9207 - val_accuracy: 0.4896 - val_loss: 3.3180 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.6040 - loss: 1.0092 - val_accuracy: 0.4948 - val_loss: 6.0546 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.6038 - loss: 0.9107 - val_accuracy: 0.5260 - val_loss: 3.2147 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.6142 - loss: 0.8099 - val_accuracy: 0.5104 - val_loss: 3.0290 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.6133 - loss: 0.6700 - val_accuracy: 0.5885 - val_loss: 2.0315 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.6711 - loss: 0.6212 - val_accuracy: 0.5990 - val_loss: 1.1004 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.6473 - loss: 0.6731 - val_accuracy: 0.6042 - val_loss: 1.1261 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.6624 - loss: 0.6129 - val_accuracy: 0.6198 - val_loss: 1.1543 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 0.7000 - loss: 0.5994 - val_accuracy: 0.6094 - val_loss: 0.9884 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7226 - loss: 0.5574 - val_accuracy: 0.6510 - val_loss: 0.7808 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7185 - loss: 0.5614 - val_accuracy: 0.6823 - val_loss: 0.8878 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7506 - loss: 0.5328 - val_accuracy: 0.7083 - val_loss: 0.7980 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7007 - loss: 0.5726 - val_accuracy: 0.7135 - val_loss: 0.7839 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7497 - loss: 0.5252 - val_accuracy: 0.6615 - val_loss: 0.7864 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7269 - loss: 0.5202 - val_accuracy: 0.7344 - val_loss: 0.6395 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.7590 - loss: 0.4997 - val_accuracy: 0.7396 - val_loss: 0.5710 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 0.7582 - loss: 0.4817 - val_accuracy: 0.8021 - val_loss: 0.4551 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7837 - loss: 0.4603 - val_accuracy: 0.7448 - val_loss: 0.5128 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.7745 - loss: 0.4842 - val_accuracy: 0.7865 - val_loss: 0.4474 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.8004 - loss: 0.4434 - val_accuracy: 0.7240 - val_loss: 0.5952 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.7843 - loss: 0.4752 - val_accuracy: 0.8021 - val_loss: 0.4301 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7789 - loss: 0.4540 - val_accuracy: 0.8229 - val_loss: 0.4069 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7857 - loss: 0.4336 - val_accuracy: 0.8073 - val_loss: 0.3874 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.7778 - loss: 0.4732 - val_accuracy: 0.8125 - val_loss: 0.3973 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.8151 - loss: 0.4095 - val_accuracy: 0.8438 - val_loss: 0.3550 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.7962 - loss: 0.4042 - val_accuracy: 0.8229 - val_loss: 0.3664 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.8166 - loss: 0.3984 - val_accuracy: 0.8125 - val_loss: 0.4343 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.7803 - loss: 0.4458 - val_accuracy: 0.8438 - val_loss: 0.3533 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.8256 - loss: 0.3894 - val_accuracy: 0.7656 - val_loss: 0.4998 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.8234 - loss: 0.3903 - val_accuracy: 0.8281 - val_loss: 0.3477 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.8134 - loss: 0.3809 - val_accuracy: 0.6979 - val_loss: 0.8108 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.8329 - loss: 0.3807 - val_accuracy: 0.6875 - val_loss: 0.7147 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.8378 - loss: 0.3496 - val_accuracy: 0.7500 - val_loss: 0.5482 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.8471 - loss: 0.3547 - val_accuracy: 0.8021 - val_loss: 0.4080 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.8498 - loss: 0.3658 - val_accuracy: 0.7604 - val_loss: 0.4818 - learning_rate: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# ใช้ Early Stopping และ ReduceLROnPlateau\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "# เทรนโมเดล\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sISR1aLKge9",
        "outputId": "46ce2d0d-969b-49c6-ea2d-9e52e7026c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 196 images belonging to 2 classes.\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 533ms/step - accuracy: 0.8724 - loss: 0.3243\n",
            "Test Accuracy: 0.8418\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_path,  \n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False\n",
        ")\n",
        "test_loss, test_acc = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF9PcfjcK0u8"
      },
      "outputs": [],
      "source": [
        "model.save(\"gender_classification2_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "T1LacaIEncp0",
        "outputId": "c50217ab-21c1-4686-e7dd-1422a866111f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ดึงชื่อคลาส\n",
        "class_labels = list(test_data.class_indices.keys())  # ['MEN', 'WOMAN']\n",
        "\n",
        "# วนลูปแสดงรูปทั้งหมดจาก Test Set\n",
        "for test_images, test_labels in test_data:\n",
        "    for i in range(len(test_images)):  # วนลูปตามจำนวนรูปใน batch\n",
        "        img = test_images[i]\n",
        "        true_label = int(test_labels[i])  # ค่าจริง\n",
        "\n",
        "        # ทำนายผล\n",
        "        pred_prob = model.predict(np.expand_dims(img, axis=0), verbose=0)[0][0]  # ขยายมิติให้เข้ากับโมเดล\n",
        "        pred_label = int(pred_prob > 0.5)\n",
        "\n",
        "        # ดึงชื่อคลาส\n",
        "        pred_class = class_labels[pred_label]\n",
        "        true_class = class_labels[true_label]\n",
        "\n",
        "        # แสดงภาพและผลลัพธ์\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Predicted: {pred_class}\\nTrue: {true_class}\\n({pred_prob:.2f})\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "AQdHG5J8s6Zc",
        "outputId": "3be9f03b-fe89-4d0c-b560-a95dec5ed678"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "model = load_model(\"gender_classification2_model.h5\")  # เปลี่ยนเป็น path ของโมเดลที่ต้องการใช้\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    img = Image.open(filename)\n",
        "    img = img.convert(\"RGB\")  # เผื่อภาพเป็นขาวดำ จะได้เปลี่ยนเป็น RGB\n",
        "    img = img.resize((128, 128))  # ปรับขนาดให้ตรงกับโมเดล\n",
        "    img = np.array(img) / 255.0  # Normalize\n",
        "    img = np.expand_dims(img, axis=0)  # เพิ่มมิติให้เข้ากับโมเดล\n",
        "\n",
        "    pred_prob = model.predict(img, verbose=0)[0][0]\n",
        "    pred_label = \"WOMAN\" if pred_prob > 0.5 else \"MEN\"\n",
        "\n",
        "    plt.imshow(img.squeeze())\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted: {pred_label}\\nConfidence: {pred_prob:.2f}\")\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
